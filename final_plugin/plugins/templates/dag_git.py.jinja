from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.operators.trigger_dagrun import TriggerDagRunOperator
from airflow.providers.ssh.operators.ssh import SSHOperator
from airflow.models import Variable
from datetime import datetime

{% set p = variable(params_var_key) %}

default_args = {
    'owner': p.get('workflow_owner', 'airflow'),
    'start_date': datetime({{ start_date_year }}, {{ start_date_month }}, {{ start_date_day }}),
}
{% set cron = 'None' if p.get('schedule_type') == 'manual' else '"' ~ p.get('schedule_interval', '@daily') ~ '"' %}

with DAG(
    dag_id='{{ dag_id }}',
    default_args=default_args,
    schedule_interval={{ cron }},
    catchup=p.get('catchup', False),
    tags=[{{ workflow_tags|tojson }}],
) as dag:
        git_clone = BashOperator(
        task_id='git_clone',
        bash_command=(
            'git clone '
            '{% if p.get("branch_or_tag") %}-b {{ p["branch_or_tag"] }} {% endif %}'
            '{{ p["repo_url"] }} '
            '{{ p.get("target_path", "/tmp/repo") }}'
        )
    )

    {% if scp_enabled %}
    scp_repo = BashOperator(
        task_id='scp_repo',
        bash_command=(
            'scp -r -o StrictHostKeyChecking=no '
            '{{ target_path }} '
            '{{ remote_user }}@{{ remote_host }}:{{ dest_path }}'
        ),
        env={
            'SSHPASS': '{{ ssh_password }}'  # optional if using sshpass or key
        }
    )
    git_clone >> scp_repo
    {% endif %}

    {% if next_dag_id %}
    trigger = TriggerDagRunOperator(
        task_id='trigger_{{ next_dag_id }}',
        trigger_dag_id='{{ next_dag_id }}'
    )
    {% if scp_enabled %}
    scp_repo >> trigger
    {% else %}
    git_clone >> trigger
    {% endif %}
    {% endif %}
